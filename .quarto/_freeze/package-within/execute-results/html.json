{
  "hash": "b298f532c2b65fc3a71d489c4429a9da",
  "result": {
    "markdown": "# The package within {#sec-package-within}\n\n\n::: {.cell}\n\n:::\n\n```{=html}\n<!--\n\nThis is still a mix of \"you\" and \"we\", but I feel like it's OK. I think there is a \"we\": we, as authors, guiding the reader (\"you\") through a learning exercise. Both parties are walking through the example, so it's OK to talk about \"we/our\" and \"you/your(s)\". Especially when describing mistakes, sometimes it feels better that \"we\" are making the mistake instead of only \"you\" the reader.\n\nUnused ideas for little data cleaning tasks:\n\n* dysfunctional missing value codes, e.g. where -99 means temp is missing\n\n* using the degree symbol properly with unicode escape sequence\n-->\n```\n\nThis part of the book ends the same way it started, with the development of a small toy package.\n@sec-whole-game established the basic mechanics, workflow, and tooling of package development, but said practically nothing about the R code inside the package.\nThis chapter focuses primarily on the package's R code and how it differs from R code in a script.\n\nStarting with a data analysis script, you learn how to find the package that lurks within.\nYou'll isolate and then extract reusable data and logic from the script, put this into an R package, and then use that package in a much simplified script.\nWe've included a few rookie mistakes along the way, in order to highlight special considerations for the R code inside a package.\n\nNote that the section headers incorporate the NATO phonetic alphabet (alfa, bravo, etc.) and have no specific meaning.\nThey are just a convenient way to mark our progress towards a working package.\nIt is fine to follow along just by reading and this chapter is completely self-contained, i.e. it's not a prerequisite for material later in the book.\nBut if you wish to see the state of specific files along the way, they can be found in the [source files for the book](https://github.com/hadley/r-pkgs/tree/main/package-within-files).\n\n## Alfa: a script that works\n\n\n```{=html}\n<!--\nThere's quite a bit of ugliness and awkwardness around paths here. But I'm not convinced it's worth it to do this properly, whatever that would even mean here.\n-->\n```\n\nLet's consider `data-cleaning.R`, a fictional data analysis script for a group that collects reports from people who went for a swim:\n\n> Where did you swim and how hot was it outside?\n\nTheir data usually comes as a CSV file, such as `swim.csv`:\n\n\n::: {.cell}\n\n```\nname,where,temp\nAdam,beach,95\nBess,coast,91\nCora,seashore,28\nDale,beach,85\nEvan,seaside,31\n```\n:::\n\n\n`data-cleaning.R` begins by reading `swim.csv` into a data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninfile <- \"swim.csv\"\n(dat <- read.csv(infile))\n```\n:::\n\n::: {.cell}\n\n```\n#>   name    where temp\n#> 1 Adam    beach   95\n#> 2 Bess    coast   91\n#> 3 Cora seashore   28\n#> 4 Dale    beach   85\n#> 5 Evan  seaside   31\n```\n:::\n\n\nThey then classify each observation as using American (\"US\") or British (\"UK\") English, based on the word chosen to describe the sandy place where the ocean and land meet.\nThe `where` column is used to build the new `english` column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$english[dat$where == \"beach\"] <- \"US\"\ndat$english[dat$where == \"coast\"] <- \"US\"\ndat$english[dat$where == \"seashore\"] <- \"UK\"\ndat$english[dat$where == \"seaside\"] <- \"UK\"\n```\n:::\n\n\nSadly, the temperatures are often reported in a mix of Fahrenheit and Celsius.\nIn the absence of better information, they guess that Americans report temperatures in Fahrenheit and therefore those observations are converted to Celsius.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$temp[dat$english == \"US\"] <- (dat$temp[dat$english == \"US\"] - 32) * 5/9\ndat\n#>   name    where temp english\n#> 1 Adam    beach 35.0      US\n#> 2 Bess    coast 32.8      US\n#> 3 Cora seashore 28.0      UK\n#> 4 Dale    beach 29.4      US\n#> 5 Evan  seaside 31.0      UK\n```\n:::\n\n\nFinally, this cleaned (cleaner?) data is written back out to a CSV file.\nThey like to capture a timestamp in the filename when they do this[^package-within-1].\n\n[^package-within-1]: `Sys.time()` returns an object of class `POSIXct`, therefore when we call `format()` on it, we are actually using `format.POSIXct()`.\n    Read the help for [`?format.POSIXct`](https://rdrr.io/r/base/strptime.html) if you're not familiar with such format strings.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow <- Sys.time()\ntimestamp <- format(now, \"%Y-%B-%d_%H-%M-%S\")\n(outfile <- paste0(timestamp, \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile)))\n#> [1] \"2023-六月-19_19-44-49_swim_clean.csv\"\nwrite.csv(dat, file = outfile, quote = FALSE, row.names = FALSE)\n```\n:::\n\n\n\n\nHere is `data-cleaning.R` in its entirety:\n\n\n```{=html}\n<!--\nAny edits to the code shown above must be manually transferred to this file.\n-->\n```\n\n::: {.cell file='package-within-files/alfa/data-cleaning.R'}\n\n```{.r .cell-code}\ninfile <- \"swim.csv\"\n(dat <- read.csv(infile))\n\ndat$english[dat$where == \"beach\"] <- \"US\"\ndat$english[dat$where == \"coast\"] <- \"US\"\ndat$english[dat$where == \"seashore\"] <- \"UK\"\ndat$english[dat$where == \"seaside\"] <- \"UK\"\n\ndat$temp[dat$english == \"US\"] <- (dat$temp[dat$english == \"US\"] - 32) * 5/9\ndat\n\nnow <- Sys.time()\ntimestamp <- format(now, \"%Y-%B-%d_%H-%M-%S\")\n(outfile <- paste0(timestamp, \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile)))\nwrite.csv(dat, file = outfile, quote = FALSE, row.names = FALSE)\n```\n:::\n\n\nEven if your typical analytical tasks are quite different, hopefully you see a few familiar patterns here.\nIt's easy to imagine that this group does very similar pre-processing of many similar data files over time.\nTheir analyses can be more efficient and consistent if they make these standard data maneuvers available to themselves as functions in a package, instead of inlining the same data and logic into dozens or hundreds of data ingest scripts.\n\n## Bravo: a better script that works\n\nThe package that lurks within the original script is actually pretty hard to see!\nIt's obscured by a few suboptimal coding practices, such as the use of repetitive copy/paste-style code and the mixing of code and data.\nTherefore a good first step is to refactor this code, isolating as much data and logic as possible in proper objects and functions, respectively.\n\nThis is also a good time to introduce the use of some add-on packages, for several reasons.\nFirst, we would actually use the tidyverse for this sort of data wrangling.\nSecond, many people use add-on packages in their scripts, so it is good to see how add-on packages are handled inside a package.\n\nHere's the new and improved version of the script.\n\n\n::: {.cell file='package-within-files/bravo/data-cleaning.R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ninfile <- \"swim.csv\"\ndat <- read_csv(infile, col_types = cols(name = \"c\", where = \"c\", temp = \"d\"))\n\nlookup_table <- tribble(\n      ~where, ~english,\n     \"beach\",     \"US\",\n     \"coast\",     \"US\",\n  \"seashore\",     \"UK\",\n   \"seaside\",     \"UK\"\n)\n\ndat <- dat %>% \n  left_join(lookup_table)\n\nf_to_c <- function(x) (x - 32) * 5/9\n\ndat <- dat %>% \n  mutate(temp = if_else(english == \"US\", f_to_c(temp), temp))\ndat\n\nnow <- Sys.time()\ntimestamp <- function(time) format(time, \"%Y-%B-%d_%H-%M-%S\")\noutfile_path <- function(infile) {\n  paste0(timestamp(now), \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\nwrite_csv(dat, outfile_path(infile))\n```\n:::\n\n\nThe key changes to note are:\n\n-   We are using functions from tidyverse packages (specifically from readr and dplyr) and we make them available with `library(tidyverse)`.\n-   The map between different \"beach\" words and whether they are considered to be US or UK English is now isolated in a lookup table, which lets us create the `english` column in one go with a `left_join()`. This lookup table makes the mapping easier to comprehend and would be much easier to extend in the future with new \"beach\" words.\n-   `f_to_c()`, `timestamp()`, and `outfile_path()` are new helper functions that hold the logic for converting temperatures and forming the timestamped output file name.\n\nIt's getting easier to recognize the reusable bits of this script, i.e. the bits that have nothing to do with a specific input file, like `swim.csv`.\nThis sort of refactoring often happens naturally on the way to creating your own package, but if it does not, it's a good idea to do this intentionally.\n\n## Charlie: a separate file for helper functions\n\nA typical next step is to move reusable data and logic out of the analysis script and into one or more separate files.\nThis is a conventional opening move, if you want to use these same helper files in multiple analyses.\n\nHere is the content of `beach-lookup-table.csv`:\n\n\n::: {.cell}\n\n```\nwhere,english\nbeach,US\ncoast,US\nseashore,UK\nseaside,UK\n```\n:::\n\n\nHere is the content of `cleaning-helpers.R`:\n\n\n::: {.cell file='package-within-files/charlie/cleaning-helpers.R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nlocalize_beach <- function(dat) {\n  lookup_table <- read_csv(\n    \"beach-lookup-table.csv\",\n    col_types = cols(where = \"c\", english = \"c\")\n  )\n  left_join(dat, lookup_table)\n}\n\nf_to_c <- function(x) (x - 32) * 5/9\n\ncelsify_temp <- function(dat) {\n  mutate(dat, temp = if_else(english == \"US\", f_to_c(temp), temp))\n}\n\nnow <- Sys.time()\ntimestamp <- function(time) format(time, \"%Y-%B-%d_%H-%M-%S\")\noutfile_path <- function(infile) {\n  paste0(timestamp(now), \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n```\n:::\n\n\nWe've added some high-level helper functions, `localize_beach()` and `celsify_temp()`, to the pre-existing helpers (`f_to_c()`, `timestamp()`, and `outfile_path()`).\n\nHere is the next version of the data cleaning script, now that we've pulled out the helper functions (and lookup table).\n\n\n::: {.cell file='package-within-files/charlie/data-cleaning.R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nsource(\"cleaning-helpers.R\")\n\ninfile <- \"swim.csv\"\ndat <- read_csv(infile, col_types = cols(name = \"c\", where = \"c\", temp = \"d\"))\n\n(dat <- dat %>% \n    localize_beach() %>% \n    celsify_temp())\n\nwrite_csv(dat, outfile_path(infile))\n```\n:::\n\n\nNotice that the script is getting shorter and, hopefully, easier to read and modify, because repetitive and fussy clutter has been moved out of sight.\nWhether the code is actually easier to work with is subjective and depends on how natural the \"interface\" feels for the people who actually preprocess swimming data.\nThese sorts of design decisions are the subject of a separate project: [design.tidyverse.org](https://design.tidyverse.org/).\n\nLet's assume the group agrees that our design decisions are promising, i.e. we seem to be making things better, not worse.\nSure, the existing code is not perfect, but this is a typical developmental stage when you're trying to figure out what the helper functions should be and how they should work.\n\n## Delta: a failed attempt at making a package\n\nWhile this first attempt to create a package will end in failure, it's still helpful to go through some common missteps, to illuminate what happens behind the scenes.\n\nHere are the simplest steps that you might take, in an attempt to convert `cleaning-helpers.R` into a proper package:\n\n-   Use `usethis::create_package(\"path/to/delta\")` to scaffold a new R package, with the name \"delta\".\n    -   This is a good first step!\n-   Copy `cleaning-helpers.R` into the new package, specifically, to `R/cleaning-helpers.R`.\n    -   This is morally correct, but mechanically wrong in several ways, as we will soon see.\n-   Copy `beach-lookup-table.csv` into the new package. But where? Let's try the top-level of the source package.\n    -   This is not going to end well. Shipping data files in a package is a special topic, which is covered in @sec-data.\n-   Install this package, perhaps using `devtools::install()` or via Ctrl + Shift + B (Windows & Linux) or Cmd + Shift + B in RStudio.\n    -   Despite all of the problems identified above, this actually works! Which is interesting, because we can (try to) use it and see what happens.\n\n\n\n\n\nHere is the next version of the data cleaning script that you hope will run after successfully installing this package (which we're calling \"delta\").\n\n\n::: {.cell file='package-within-files/delta-data-cleaning.R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(delta)\n\ninfile <- \"swim.csv\"\ndat <- read_csv(infile, col_types = cols(name = \"c\", where = \"c\", temp = \"d\"))\n\ndat <- dat %>% \n  localize_beach() %>% \n  celsify_temp()\n\nwrite_csv(dat, outfile_path(infile))\n```\n:::\n\n\nThe only change from our previous script is that\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"cleaning-helpers.R\")\n```\n:::\n\n\nhas been replaced by\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(delta)\n```\n:::\n\n\nHere's what actually happens if you install the delta package and try to run the data cleaning script:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(delta)\n\ninfile <- \"swim.csv\"\ndat <- read_csv(infile, col_types = cols(name = \"c\", where = \"c\", temp = \"d\"))\n\ndat <- dat %>% \n  localize_beach() %>% \n  celsify_temp()\n#> Error in localize_beach(.) : could not find function \"localize_beach\"\n\nwrite_csv(dat, outfile_path(infile))\n#> Error in outfile_path(infile) : could not find function \"outfile_path\"\n```\n:::\n\n\nNone of the helper functions are actually available for use, even though you call `library(delta)`!\nIn contrast to `source()`ing a file of helper functions, attaching a package does not dump its functions into the global workspace.\nBy default, functions in a package are only for internal use.\nYou need to export `localize_beach()`, `celsify_temp()`, and `outfile_path()` so your users can call them.\nIn the devtools workflow, we achieve this by putting `@export` in the special roxygen comment above each function (namespace management is covered in @sec-dependencies-NAMESPACE-workflow), like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' @export\ncelsify_temp <- function(dat) {\n  mutate(dat, temp = if_else(english == \"US\", f_to_c(temp), temp))\n}\n```\n:::\n\n\nAfter you add the `@export` tag to `localize_beach()`, `celsify_temp()`, and `outfile_path()`, you run `devtools::document()` to (re)generate the `NAMESPACE` file, and re-install the delta package.\nNow when you re-execute the data cleaning script, it works!\n\n\n\n\n\nCorrection: it *sort of* works *sometimes*.\nSpecifically, it works if and only if the working directory is set to the top-level of the source package.\nFrom any other working directory, you still get an error:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat %>% \n  localize_beach() %>% \n  celsify_temp()\n#> Error: 'beach-lookup-table.csv' does not exist in current working directory ('/Users/jenny/tmp').\n```\n:::\n\n\nThe lookup table consulted inside `localize_beach()` cannot be found.\nOne does not simply dump CSV files into the source of an R package and expect things to \"just work\".\nWe will fix this in our next iteration of the package (@sec-data has full coverage of how to include data in a package).\n\nBefore we abandon this initial experiment, let's also marvel at the fact that you were able to install, attach, and, to a certain extent, use a fundamentally broken package.\n`devtools::load_all()` works fine, too!\nThis is a sobering reminder that you should be running `R CMD check`, probably via `devtools::check()`, very often during development.\nThis will quickly alert you to many problems that simple installation and usage does not reveal.\n\nIndeed, `check()` fails for this package and you see this:\n\n```         \n * installing *source* package ‘delta’ ...\n ** using staged installation\n ** R\n ** byte-compile and prepare package for lazy loading\n Error in library(tidyverse) : there is no package called ‘tidyverse’\n Error: unable to load R code in package ‘delta’\n Execution halted\n ERROR: lazy loading failed for package ‘delta’\n * removing ‘/Users/jenny/rrr/delta.Rcheck/delta’\n```\n\nWhat do you mean \"there is no package called 'tidyverse'\"?!?\nWe're using it, with no problems, in our main script!\nAlso, we've already installed and used this package, why can't `R CMD check` find it?\n\nThis error is what happens when the strictness of `R CMD check` meets the very first line of `R/cleaning-helpers.R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\nThis is *not* how you declare that your package depends on another package (the tidyverse, in this case).\nThis is *also not* how you make functions in another package available for use in yours.\nDependencies must be declared in `DESCRIPTION` (and that's not all).\nSince we declared no dependencies, `R CMD check` takes us at our word and tries to install our package with only the base packages available, which means this `library(tidyverse)` call fails.\nA \"regular\" installation succeeds, simply because the tidyverse is available in your regular library, which hides this particular mistake.\n\nTo review, copying `cleaning-helpers.R` to `R/cleaning-helpers.R`, without further modification, was problematic in (at least) the following ways:\n\n-   Does not account for exported vs. non-exported functions.\n-   The CSV file holding our lookup table cannot be found in the installed package.\n-   Does not properly declare our dependency on other add-on packages.\n\n## Echo: a working package\n\nWe're ready to make the most minimal version of this package that actually works.\n\n\n\n\n\nHere is the new version of `R/cleaning-helpers.R`[^package-within-2]:\n\n[^package-within-2]: Putting everything in one file, with this name, is not ideal, but it is technically allowed.\n    We discuss organising and naming the files below `R/` in @sec-code-organising.\n\n\n::: {.cell file='package-within-files/echo/R/cleaning-helpers.R'}\n\n```{.r .cell-code}\nlookup_table <- dplyr::tribble(\n      ~where, ~english,\n     \"beach\",     \"US\",\n     \"coast\",     \"US\",\n  \"seashore\",     \"UK\",\n   \"seaside\",     \"UK\"\n)\n\n#' @export\nlocalize_beach <- function(dat) {\n  dplyr::left_join(dat, lookup_table)\n}\n\nf_to_c <- function(x) (x - 32) * 5/9\n\n#' @export\ncelsify_temp <- function(dat) {\n  dplyr::mutate(dat, temp = dplyr::if_else(english == \"US\", f_to_c(temp), temp))\n}\n\nnow <- Sys.time()\ntimestamp <- function(time) format(time, \"%Y-%B-%d_%H-%M-%S\")\n\n#' @export\noutfile_path <- function(infile) {\n  paste0(timestamp(now), \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n```\n:::\n\n\nWe've gone back to defining the `lookup_table` with R code, since the initial attempt to read it from CSV created some sort of filepath snafu.\nThis is OK for small, internal, static data, but remember to see @sec-data for more general techniques for storing data in a package.\n\nAll of the calls to tidyverse functions have now been qualified with the name of the specific package that actually provides the function, e.g. `dplyr::mutate()`.\nThere are other ways to access functions in another package, explained in @sec-dependencies-in-imports, but this is our recommended default.\nIt is also our strong recommendation that no one depend on the tidyverse meta-package in a package[^package-within-3].\nInstead, it is better to identify the specific package(s) you actually use.\nIn this case, the package only uses dplyr.\n\n[^package-within-3]: The blog post [The tidyverse is for EDA, not packages](https://www.tidyverse.org/blog/2018/06/tidyverse-not-for-packages/) elaborates on this.\n\nThe `library(tidyverse)` call is gone and instead we declare the use of dplyr in the `Imports` field of `DESCRIPTION`:\n\n```         \nPackage: echo\n(... other lines omitted ...)\nImports: \n    dplyr\n```\n\nThis, together with the use of namespace-qualified calls, like `dplyr::left_join()`, constitutes a valid way to use another package within yours.\nThe metadata conveyed via `DESCRIPTION` is covered in @sec-description.\n\nAll of the user-facing functions have an `@export` tag in their roxygen comment, which means that `devtools::document()` adds them correctly to the `NAMESPACE` file.\nNote that `f_to_c()` is currently only used internally, inside `celsify_temp()`, so it is not exported (likewise for `timestamp()`).\n\nThis version of the package can be installed, used, AND it technically passes `R CMD check`, though with 1 warning and 1 note.\n\n```         \n* checking for missing documentation entries ... WARNING\nUndocumented code objects:\n  ‘celsify_temp’ ‘localize_beach’ ‘outfile_path’\nAll user-level objects in a package should have documentation entries.\nSee chapter ‘Writing R documentation files’ in the ‘Writing R\nExtensions’ manual.\n\n* checking R code for possible problems ... NOTE\ncelsify_temp: no visible binding for global variable ‘english’\ncelsify_temp: no visible binding for global variable ‘temp’\nUndefined global functions or variables:\n  english temp\n```\n\nThe \"no visible binding\" note is a peculiarity of using dplyr and unquoted variable names inside a package, where the use of bare variable names (`english` and `temp`) looks suspicious.\nYou can add either of these lines to any file below `R/` to eliminate this note (such as the package-level documentation file described in @sec-man-package-doc):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# option 1 (then you should also put utils in Imports)\nutils::globalVariables(c(\"english\", \"temp\"))\n\n# option 2\nenglish <- temp <- NULL\n```\n:::\n\n\nWe're seeing that it can be tricky to program around a package like dplyr, which makes heavy use of nonstandard evaluation.\nBehind the scenes, that is the technique that allows dplyr's end users to use bare (not quoted) variable names.\nPackages like dplyr prioritize the experience of the typical end user, at the expense of making them trickier to depend on.\nThe two options shown above for suppressing the \"no visible binding\" note, represent entry-level solutions.\nFor a more sophisticated treatment of these issues, see `vignette(\"in-packages\", package = \"dplyr\")` and `vignette(\"programming\", package = \"dplyr\")`.\n\nThe warning about missing documentation is because the exported functions have not been properly documented.\nThis is a valid concern and something you should absolutely address in a real package.\nYou've already seen how to create help files with roxygen comments in @sec-whole-game-document and we cover this topic thoroughly in @sec-man.\n\n## Foxtrot: build time vs. run time {#sec-package-within-build-time-run-time}\n\nThe echo package works, which is great, but group members notice something odd about the timestamps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.time()\n#> [1] \"2023-03-26 22:48:48 PDT\"\n\noutfile_path(\"INFILE.csv\")\n#> [1] \"2020-September-03_11-06-33_INFILE_clean.csv\"\n```\n:::\n\n\nThe datetime in the timestamped filename doesn't reflect the time reported by the system.\nIn fact, the users claim that the timestamp never seems to change at all!\nWhy is this?\n\nRecall how we form the filepath for output files:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow <- Sys.time()\ntimestamp <- function(time) format(time, \"%Y-%B-%d_%H-%M-%S\")\noutfile_path <- function(infile) {\n  paste0(timestamp(now), \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n```\n:::\n\n\nThe fact that we capture `now <- Sys.time()` outside of the definition of `outfile_path()` has probably been vexing some readers for a while.\n`now` reflects the instant in time when we execute `now <- Sys.time()`.\nIn the initial approach, `now` was assigned when we `source()`d `cleaning-helpers.R`.\nThat's not ideal, but it was probably a pretty harmless mistake, because the helper file would be `source()`d shortly before we wrote the output file.\n\nBut this approach is quite devastating in the context of a package.\n`now <- Sys.time()` is executed **when the package is built**[^package-within-4].\nAnd never again.\nIt is very easy to assume your package code is re-evaluated when the package is attached or used.\nBut it is not.\nYes, the code *inside your functions* is absolutely run whenever they are called.\nBut your functions -- and any other objects created in top-level code below `R/` -- are defined exactly once, at build time.\n\n[^package-within-4]: Here we're referring to when the package code is compiled, which could be either when the binary is made (for macOS or Windows; @sec-structure-binary) or when the package is installed from source (@sec-installed-package).\n\nBy defining `now` with top-level code below `R/`, we've doomed our package to timestamp all of its output files with the same (wrong) time.\nThe fix is to make sure the `Sys.time()` call happens at run time.\n\nLet's look again at parts of `R/cleaning-helpers.R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlookup_table <- dplyr::tribble(\n      ~where, ~english,\n     \"beach\",     \"US\",\n     \"coast\",     \"US\",\n  \"seashore\",     \"UK\",\n   \"seaside\",     \"UK\"\n)\n\nnow <- Sys.time()\ntimestamp <- function(time) format(time, \"%Y-%B-%d_%H-%M-%S\")\noutfile_path <- function(infile) {\n  paste0(timestamp(now), \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n```\n:::\n\n\nThere are four top-level `<-` assignments in this excerpt.\nThe top-level definitions of the data frame `lookup_table` and the functions `timestamp()` and `outfile_path()` are correct.\nIt is appropriate that these be defined exactly once, at build time.\nThe top-level definition of `now`, which is then used inside `outfile_path()`, is regrettable.\n\nHere are better versions of `outfile_path()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# always timestamp as \"now\"\noutfile_path <- function(infile) {\n  ts <- timestamp(Sys.time())\n  paste0(ts, \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n\n# allow user to provide a time, but default to \"now\"\noutfile_path <- function(infile, time = Sys.time()) {\n  ts <- timestamp(time)\n  paste0(ts, \"_\", sub(\"(.*)([.]csv$)\", \"\\\\1_clean\\\\2\", infile))\n}\n```\n:::\n\n\nThis illustrates that you need to have a different mindset when defining objects inside a package.\nThe vast majority of those objects should be functions and these functions should generally only use data they create or that is passed via an argument.\nThere are some types of sloppiness that are fairly harmless when a function is defined immediately before its use, but that can be more costly for functions distributed as a package.\n\n## Golf: side effects {#sec-package-within-side-effects}\n\nThe timestamps now reflect the current time, but the group raises a new concern.\nAs it stands, the timestamps reflect who has done the data cleaning and which part of the world they're in.\nThe heart of the timestamp strategy is this format string[^package-within-5]:\n\n[^package-within-5]: `Sys.time()` returns an object of class `POSIXct`, therefore when we call `format()` on it, we are actually using `format.POSIXct()`.\n    Read the help for [`?format.POSIXct`](https://rdrr.io/r/base/strptime.html) if you're not familiar with such format strings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformat(Sys.time(), \"%Y-%B-%d_%H-%M-%S\")\n#> [1] \"2023-六月-19_19-44-50\"\n```\n:::\n\n\nThis formats `Sys.time()` in such a way that it includes the month *name* (not number) and the local time[^package-within-6].\n\n[^package-within-6]: It would clearly be better to format according to ISO 8601, which encodes the month by number, but please humor me for the sake of making this example more obvious.\n\n@tbl-timestamps shows what happens when such a timestamp is produced by several hypothetical colleagues cleaning some data at exactly the same instant in time.\n\n\n\n\n::: {#tbl-timestamps .cell tbl-cap='Timestamp varies by locale and timezone.'}\n::: {.cell-output-display}\n|location           |timestamp                  |LC_TIME     |tz                |\n|:------------------|:--------------------------|:-----------|:-----------------|\n|Rome, Italy        |2020-settembre-05_00-30-00 |it_IT.UTF-8 |Europe/Rome       |\n|Warsaw, Poland     |2020-wrzesień-05_00-30-00  |pl_PL.UTF-8 |Europe/Warsaw     |\n|Sao Paulo, Brazil  |2020-setembro-04_19-30-00  |pt_BR.UTF-8 |America/Sao_Paulo |\n|Greenwich, England |2020-September-04_23-30-00 |en_GB.UTF-8 |Europe/London     |\n|\"Computer World!\"  |2020-September-04_22-30-00 |C           |UTC               |\n:::\n:::\n\n\nNote that the month names vary, as does the time, and even the date!\nThe safest choice is to form timestamps with respect to a fixed locale and time zone (presumably the non-geographic choices represented by \"Computer World!\" above).\n\nYou do some research and learn that you can force a certain locale via `Sys.setlocale()` and force a certain time zone by setting the TZ environment variable.\nSpecifically, we set the LC_TIME component of the locale to \"C\" and the time zone to \"UTC\" (Coordinated Universal Time).\nHere's your first attempt to improve `timestamp()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimestamp <- function(time = Sys.time()) {\n  Sys.setlocale(\"LC_TIME\", \"C\")\n  Sys.setenv(TZ = \"UTC\")\n  format(time, \"%Y-%B-%d_%H-%M-%S\")\n}\n```\n:::\n\n\nBut your Brazilian colleague notices that datetimes print differently, before and after she uses `outfile_path()` from your package:\n\nBefore:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformat(Sys.time(), \"%Y-%B-%d_%H-%M-%S\")\n```\n:::\n\n::: {.cell}\n\n```\n#> [1] \"2023-junho-19_08-44-51\"\n```\n:::\n\n\nAfter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutfile_path(\"INFILE.csv\")\n#> [1] \"2023-June-19_11-44-50_INFILE_clean.csv\"\n\nformat(Sys.time(), \"%Y-%B-%d_%H-%M-%S\")\n#> [1] \"2023-June-19_11-44-51\"\n```\n:::\n\n\n\n\nNotice that her month name switched from Portuguese to English and the time is clearly being reported in a different time zone.\nThe calls to `Sys.setlocale()` and `Sys.setenv()` inside `timestamp()` have made persistent (and very surprising) changes to her R session.\nThis sort of side effect is very undesirable and is extremely difficult to track down and debug, especially in more complicated settings.\n\nHere are better versions of `timestamp()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use withr::local_*() functions to keep the changes local to timestamp()\ntimestamp <- function(time = Sys.time()) {\n  withr::local_locale(c(\"LC_TIME\" = \"C\"))\n  withr::local_timezone(\"UTC\")\n  format(time, \"%Y-%B-%d_%H-%M-%S\")\n}\n\n# use the tz argument to format.POSIXct()\ntimestamp <- function(time = Sys.time()) {\n  withr::local_locale(c(\"LC_TIME\" = \"C\"))\n  format(time, \"%Y-%B-%d_%H-%M-%S\", tz = \"UTC\")\n}\n\n# put the format() call inside withr::with_*()\ntimestamp <- function(time = Sys.time()) {\n  withr::with_locale(\n    c(\"LC_TIME\" = \"C\"),\n    format(time, \"%Y-%B-%d_%H-%M-%S\", tz = \"UTC\")\n  )\n}\n```\n:::\n\n\nThese show various methods to limit the scope of our changes to LC_TIME and the timezone.\nA good rule of thumb is to make the scope of such changes as narrow as is possible and practical.\nThe `tz` argument of `format()` is the most surgical way to deal with the timezone, but nothing similar exists for LC_TIME.\nWe make the temporary locale modification using the withr package, which provides a very flexible toolkit for temporary state changes.\nThis (and `base::on.exit()`) are discussed further in @sec-code-r-landscape.\nNote that if you use withr as we do above, you would need to list it in `DESCRIPTION` in `Imports` (@sec-dependencies-in-practice, @sec-dependencies-tidyverse).\n\nThis underscores a point from the previous section: you need to adopt a different mindset when defining functions inside a package.\nTry to avoid making any changes to the user's overall state.\nIf such changes are unavoidable, make sure to reverse them (if possible) or to document them explicitly (if related to the function's primary purpose).\n\n## Concluding thoughts\n\nFinally, after several iterations, we have successfully extracted the repetitive data cleaning code for the swimming survey into an R package.\nThis example concludes the first part of book and marks the transition into more detailed reference material on specific package components.\nBefore we move on, let's review the lessons learned in this chapter.\n\n### Script vs.package\n\nWhen you first hear that expert R users often put their code into packages, you might wonder exactly what that means.\nSpecifically, what happens to your existing R scripts, R Markdown reports, and Shiny apps?\nDoes all of that code somehow get put into a package?\nThe answer is \"no\", in most contexts.\n\nTypically, you identify certain recurring operations that occur across multiple projects and this is what you extract into an R package.\nYou will still have R scripts, R Markdown reports, and Shiny apps, but by moving specific pieces of code into a formal package, your data products tend to become more concise and easier to maintain.\n\n### Finding the package within\n\nAlthough the example in this chapter is rather simple, it still captures the typical process of developing an R package for personal or organizational use.\nYou typically start with a collection of idiosyncratic and related R scripts, scattered across different projects.\nOver time, you begin to notice that certain needs come up over and over again.\n\nEach time you revisit a similar analysis, you might try to elevate your game a bit, compared to the previous iteration.\nYou refactor copy/paste-style code using more robust patterns and start to encapsulate key \"moves\" in helper functions, which might eventually migrate into their own file.\nOnce you reach this stage, you're in a great position to take the next step and create a package.\n\n### Package code is different\n\nWriting package code is a bit different from writing R scripts and it's natural to feel some discomfort when making this adjustment.\nHere are the most common gotchas that trip many of us up at first:\n\n-   Package code requires new ways of working with functions in other packages. The `DESCRIPTION` file is the principle way to declare dependencies; we don't do this via `library(somepackage)`.\n-   If you want data or files to be persistently available, there are package-specific methods of storage and retrieval. You can't just put files in the package and hope for the best.\n-   It's necessary to be explicit about which functions are user-facing and which are internal helpers. By default, functions are not exported for use by others.\n-   A new level of discipline is required to ensure that code runs at the intended time (build time vs. run time) and that there are no unintended side effects.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}